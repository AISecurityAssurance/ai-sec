# Security Analyst Backend Configuration

# Environment
ENVIRONMENT=development
DEBUG=true
SECRET_KEY=your-secret-key-here-change-in-production

# API Configuration
API_PREFIX=/api/v1
ALLOWED_ORIGINS=http://localhost:5173,http://localhost:5174,http://localhost:3000

# Database Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=security_analyst
POSTGRES_USER=sa_user
POSTGRES_PASSWORD=sa_password

REDIS_HOST=localhost
REDIS_PORT=6379
# REDIS_PASSWORD=redis_password_if_needed

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=neo4j_password

# Model Providers Configuration
# Active provider: anthropic, openai, groq, gemini, ollama
ACTIVE_PROVIDER=anthropic
ENABLE_MODEL_FALLBACK=true
MODEL_FALLBACK_ORDER=anthropic,openai,groq

# Anthropic (Claude)
# ANTHROPIC_API_KEY=your-anthropic-api-key
# ANTHROPIC_MODEL=claude-3-opus-20240229
# ANTHROPIC_TEMPERATURE=0.7
# ANTHROPIC_MAX_TOKENS=4096

# OpenAI (GPT)
# OPENAI_API_KEY=your-openai-api-key
# OPENAI_MODEL=gpt-4-turbo-preview
# OPENAI_TEMPERATURE=0.7
# OPENAI_MAX_TOKENS=4096

# Groq
# GROQ_API_KEY=your-groq-api-key
# GROQ_MODEL=llama2-70b-4096
# GROQ_TEMPERATURE=0.7
# GROQ_MAX_TOKENS=4096

# Google Gemini
# GEMINI_API_KEY=your-gemini-api-key
# GEMINI_MODEL=gemini-pro
# GEMINI_TEMPERATURE=0.7
# GEMINI_MAX_TOKENS=4096

# Ollama (Local)
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama2
OLLAMA_TEMPERATURE=0.7
OLLAMA_MAX_TOKENS=4096

# Performance Settings
MAX_CONCURRENT_ANALYSES=10
ANALYSIS_TIMEOUT_SECONDS=300
ENABLE_CACHING=true
CACHE_TTL_SECONDS=3600

# JWT Settings
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30